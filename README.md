# üîç JSON-LD Validator - Complete Dataset Creation Pipeline

Outil automatis√© en 2 workflows pour cr√©er un dataset de haute qualit√© de JSON-LD optimis√©s pour le fine-tuning de LLMs.

## üéØ Objectif

Cr√©er un dataset de **1500-2000 exemples de JSON-LD de qualit√© exceptionnelle** (score ‚â• 80/100) optimis√©s pour l'indexation par les IA (ChatGPT, Perplexity, Gemini, etc.).

## üîÑ Pipeline en 2 Workflows

### **Workflow 0 : Discovery** üîç
Analyse 240 domaines et d√©couvre 3500-4000 URLs prometteuses via sitemap.xml

### **Workflow 1 : Validation** ‚úÖ  
Scrape, valide et score les URLs d√©couvertes pour cr√©er le dataset final

## üìã Workflow 0 : Discovery (URL Discovery)

### Objectif
Analyser 240 domaines de qualit√© et d√©couvrir **3500-4000 URLs** prometteuses contenant potentiellement du JSON-LD de qualit√©.

### Fonctionnement
1. **Parse sitemap.xml** de chaque domaine
2. **Filtre** selon patterns prioritaires (FAQ, HowTo, Article, etc.)
3. **Score** chaque URL (0-100) selon :
   - Match avec patterns prioritaires (40%)
   - Profondeur optimale dans le site (20%)
   - Propret√© de l'URL (15%)
   - Priorit√© sitemap (15%)
   - Type de contenu d√©tect√© (10%)
4. **S√©lectionne** les N meilleures URLs par domaine :
   - Sites GOLD : 100 URLs max
   - Sites HIGH : 50 URLs max  
   - Sites STANDARD : 30 URLs max

### Input
`data/domains_master.json` - 240 domaines class√©s par tier et cat√©gorie

### Output
- `data/discovered_urls.json` - 3500-4000 URLs scor√©es et pr√™tes
- `output/discovery_report.md` - Rapport d√©taill√©
- `output/discovery.log` - Logs complets

### Ex√©cution

**Local:**
```bash
python -m src.discovery data/domains_master.json
```

**GitHub Actions:**
1. Aller dans l'onglet "Actions"
2. S√©lectionner "Workflow 0 - URL Discovery"
3. Cliquer "Run workflow"

**Dur√©e:** ~30-60 minutes pour 240 domaines

---

## üìä Scoring Criteria (Total: 100 points + bonus)

| Crit√®re | Poids | Description |
|---------|-------|-------------|
| **Validation syntaxique** | 15% | JSON valide + structure JSON-LD correcte |
| **Compl√©tude** | 30% | % de propri√©t√©s remplies (requises + recommand√©es) |
| **Conformit√© Google** | 25% | Propri√©t√©s requises selon Google pr√©sentes |
| **Richesse s√©mantique** | 20% | @id, sameAs, entit√©s imbriqu√©es |
| **Sp√©cificit√© du type** | 10% | Utilisation du type le plus sp√©cifique |
| **Bonus IA** | +10 | Types prioritaires (FAQPage, HowTo, Article, etc.) |

**Seuil d'acceptation:** ‚â• 80/100

## üöÄ Installation

### Pr√©requis
- Python 3.9+
- Git

### Setup local

```bash
# Cloner le repo
git clone <votre-repo>
cd json-ld-validator

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer les d√©pendances
pip install -r requirements.txt
```

## üìù Configuration

### Fichier d'entr√©e: `data/input_urls.json`

Deux formats support√©s:

**Format simple (liste d'URLs):**
```json
[
  "https://example.com/page1",
  "https://example.com/page2"
]
```

**Format enrichi (recommand√©):**
```json
[
  {
    "url": "https://example.com/page1",
    "category": "ecommerce",
    "priority": 1,
    "note": "Product page example"
  }
]
```

### Param√®tres: `src/config.py`

Personnalisable:
- `MIN_SCORE_THRESHOLD`: Seuil minimum (d√©faut: 80)
- `RATE_LIMIT_DELAY`: D√©lai entre requ√™tes (d√©faut: 2s)
- `REQUEST_TIMEOUT`: Timeout par URL (d√©faut: 15s)
- `RESPECT_ROBOTS_TXT`: Respecter robots.txt (d√©faut: True)

## üîß Utilisation

### Ex√©cution locale

```bash
# Avec le fichier par d√©faut
python -m src.main data/input_urls.json

# Avec un fichier custom
python -m src.main path/to/your/urls.json
```

### Ex√©cution via GitHub Actions

1. **Push votre fichier d'URLs** dans `data/input_urls.json`
2. **Aller dans l'onglet "Actions"** du repo GitHub
3. **S√©lectionner "JSON-LD Local Validation"**
4. **Cliquer "Run workflow"**
5. **Optionnel:** Sp√©cifier un fichier d'entr√©e diff√©rent

Les r√©sultats seront disponibles dans les artifacts (~90 jours de r√©tention).

## üìÅ Outputs

Tous les fichiers sont g√©n√©r√©s dans le dossier `output/`:

### 1. `accepted_local.jsonl` ‚úÖ
Dataset final des URLs accept√©es (score ‚â• 80).

**Format:**
```json
{
  "url": "https://example.com/page",
  "passed": true,
  "score": 87.5,
  "schema_type": "Article",
  "json_ld": {...},
  "breakdown": {
    "syntax": 15.0,
    "completeness": 26.0,
    "google_conformity": 22.5,
    "semantic_richness": 15.0,
    "type_specificity": 7.0,
    "ai_priority_bonus": 10.0
  },
  "validation_details": {...},
  "timestamp": "2024-01-16T10:30:00Z"
}
```

### 2. `rejected_local.jsonl` ‚ùå
URLs rejet√©es avec raison.

**Format:**
```json
{
  "url": "https://bad-example.com",
  "passed": false,
  "rejection_reason": "score_too_low (72.3/80)",
  "score": 72.3,
  "timestamp": "2024-01-16T10:35:00Z"
}
```

### 3. `validation_report.md` üìä
Rapport Markdown d√©taill√© avec:
- R√©sum√© ex√©cutif
- Breakdown par score, type de schema
- Raisons de rejet
- Top 10 des meilleures URLs
- Distribution des scores
- Recommandations

### 4. `detailed_report.json` üìà
Rapport JSON complet avec toutes les m√©triques pour analyse programmatique.

### 5. `scraping.log` üìù
Logs d√©taill√©s de l'ex√©cution.

## üèÜ Sites "Gold Standard" Inclus

Le fichier `data/input_urls.json` contient 10 URLs de r√©f√©rence:

| Site | Type Schema | Performance Document√©e |
|------|-------------|------------------------|
| Amazon | Product | Rich results standards |
| Food Network | Recipe | +35% traffic |
| The Guardian | NewsArticle | Author attribution gold standard |
| Eventbrite | Event | +100% growth |
| Nestl√© | Organization | +82% CTR |
| StyleCraze | HowTo | +20% CTR |
| GOV.UK | Government | Public implementation docs |
| The Verge | Article | Clean implementation |
| Brainly | QAPage | Early adopter |
| Jobrapido | JobPosting | -15% bounce rate |

**Ajoutez vos propres URLs** en compl√©tant ce fichier.

## üîç D√©tails Techniques

### Respect des bonnes pratiques

‚úÖ **Robots.txt:** V√©rifi√© avant chaque scraping  
‚úÖ **Rate limiting:** 2 secondes entre requ√™tes (configurable)  
‚úÖ **User-Agent:** Identifiable (`AIDatasetBot/1.0`)  
‚úÖ **Timeout:** 15s max par URL avec retry (2x)  
‚úÖ **Checkpoints:** Sauvegarde tous les 100 URLs  

### Validation en 5 couches

1. **Syntaxe JSON:** JSON valide + structure de base
2. **Structure JSON-LD:** @context + @type + schema.org
3. **Propri√©t√©s Schema.org:** Requises + recommand√©es par type
4. **Richesse s√©mantique:** @id, sameAs, imbrication
5. **Sp√©cificit√©:** Type le plus pr√©cis de la hi√©rarchie

### Types Schema.org Support√©s

50+ types incluant:
- Articles: Article, NewsArticle, BlogPosting
- Commerce: Product, Offer, Review, AggregateRating
- Food: Recipe, NutritionInformation
- QA: FAQPage, QAPage, Question, Answer, HowTo
- Events: Event, Place
- Jobs: JobPosting
- Organizations: Organization, LocalBusiness, Person
- Media: VideoObject, Book, SoftwareApplication
- Et plus...

## üìä Exemples de Rapports

### R√©sum√© typique

```
Total URLs scanned: 5000
‚úÖ Accepted: 3421 (68.4%)
‚ùå Rejected: 1579 (31.6%)
‚è±Ô∏è Duration: 3h 42m

Top rejection reasons:
- no_jsonld_found: 876 (55.5%)
- score_too_low: 432 (27.4%)
- invalid_json: 198 (12.5%)
```

### Score distribution

```
90-95: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 842
85-89: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 1234
80-84: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 1345
```

## üîÑ Workflow 2 (√Ä venir)

Une fois les URLs accept√©es, vous pourrez ex√©cuter le **Workflow 2** qui:
- Lit `accepted_local.jsonl`
- Valide via l'API Google Rich Results Test
- Traite 200 URLs/jour (quota gratuit)
- G√©n√®re le dataset final ultra-qualit√©

## üêõ Troubleshooting

### Probl√®me: Trop de rejets (>70%)

**Solutions:**
- V√©rifier que les URLs ont bien du JSON-LD
- Baisser le seuil dans `config.py` (ex: 70 au lieu de 80)
- Am√©liorer la qualit√© des URLs sources

### Probl√®me: "Blocked by robots.txt"

**Solutions:**
- V√©rifier le fichier robots.txt du site
- D√©sactiver temporairement: `RESPECT_ROBOTS_TXT = False` (d√©conseill√©)

### Probl√®me: Timeouts fr√©quents

**Solutions:**
- Augmenter `REQUEST_TIMEOUT` dans config.py
- Augmenter `MAX_RETRIES`

### Probl√®me: Rate limited par les sites

**Solutions:**
- Augmenter `RATE_LIMIT_DELAY` (ex: 5 secondes)
- Traiter en plusieurs batches

## üìö Ressources

- [Schema.org Vocabulary](https://schema.org)
- [Google Structured Data Guidelines](https://developers.google.com/search/docs/appearance/structured-data)
- [JSON-LD Specification](https://json-ld.org)

## ü§ù Contribution

Les PRs sont les bienvenues ! Notamment pour:
- Ajouter des types Schema.org
- Am√©liorer les r√®gles de scoring
- Optimiser les performances
- Ajouter des tests

## üìÑ License

MIT License - Libre d'utilisation pour vos projets de fine-tuning LLM.

## üôè Acknowledgments

Bas√© sur les guidelines officielles de:
- Schema.org
- Google Search Console
- √âtudes de cas document√©es (Eventbrite, Food Network, etc.)

---

**Pr√™t √† cr√©er votre dataset de qualit√© ? üöÄ**

```bash
python -m src.main data/input_urls.json
```
